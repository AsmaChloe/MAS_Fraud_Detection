{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from imblearn.pipeline import Pipeline\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#Chargement des données\n",
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "#Normalisation des colonnes\n",
    "data[\"Amount\"] = StandardScaler().fit_transform(data[[\"Amount\"]])\n",
    "data[\"Time\"] = StandardScaler().fit_transform(data[[\"Time\"]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Algorithmes de ré-échantillonage"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree_clf = DecisionTreeClassifier(random_state = 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sur-échantillonage"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RandomOverSampler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "pipeline_ros = Pipeline(steps=[('over', RandomOverSampler(random_state=0)), ('model', decision_tree_clf)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "decision_tree_clf_ros_results = cross_validate(pipeline_ros, X, y, cv=cv, n_jobs = -1, scoring = \"f1\", return_train_score=True, return_estimator=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score : 0.567\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean F1-score : {:.3f}\".format(np.mean(decision_tree_clf_ros_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#save best model\n",
    "best_model = decision_tree_clf_ros_results['estimator'][np.argmax(decision_tree_clf_ros_results['test_score'])]\n",
    "filename = './modeles/decision_tree_clf_ros_results.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SMOTE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'smote__sampling_strategy': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "}\n",
    "\n",
    "pipeline_smote = Pipeline(steps=[('smote', SMOTE(random_state=0)), ('model', decision_tree_clf)])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mean F1-score : 0.995\n",
      "Best parameters :  {'smote__sampling_strategy': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline_smote,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1_micro\",\n",
    "    n_jobs=-1,\n",
    "    error_score='raise'  # raise an error if any fit fails\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV object on the data\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best mean score and the corresponding parameters\n",
    "print(\"Best mean F1-score : {:.3f}\".format(grid_search.best_score_))\n",
    "print(\"Best parameters : \", grid_search.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "pipeline_smote_results = cross_validate(pipeline_smote, X, y, cv=cv, n_jobs = -1, scoring = \"f1_micro\", return_train_score=True, return_estimator=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score : 0.995\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean F1-score : {:.3f}\".format(np.mean(pipeline_smote_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "#save best model\n",
    "best_model = pipeline_smote_results['estimator'][np.argmax(pipeline_smote_results['test_score'])]\n",
    "filename = './modeles/decision_tree_clf_smote_results.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bordeline SMOTE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'smote__sampling_strategy': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "}\n",
    "\n",
    "pipeline_bordeline_smote = Pipeline(steps=[('smote', BorderlineSMOTE(random_state=0)), ('model', decision_tree_clf)])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mean F1-score : 0.916\n",
      "Best parameters :  {'smote__sampling_strategy': 0.5}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline_bordeline_smote,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1_micro\",\n",
    "    n_jobs=-1,\n",
    "    error_score='raise'  # raise an error if any fit fails\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV object on the data\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best mean score and the corresponding parameters\n",
    "print(\"Best mean F1-score : {:.3f}\".format(grid_search.best_score_))\n",
    "print(\"Best parameters : \", grid_search.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "pipeline_bordeline_smote_results = cross_validate(pipeline_bordeline_smote, X, y, cv=cv, n_jobs = -1, scoring = \"f1_micro\", return_train_score=True, return_estimator=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score : 0.909\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean F1-score : {:.3f}\".format(np.mean(pipeline_bordeline_smote_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "#save best model\n",
    "best_model = pipeline_bordeline_smote_results['estimator'][np.argmax(pipeline_bordeline_smote_results['test_score'])]\n",
    "filename = './modeles/decision_tree_clf_bordeline_smote_results.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### K-Means SMOTE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'smote__sampling_strategy': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "}\n",
    "\n",
    "pipeline_kmeans_smote = Pipeline(steps=[('smote', KMeansSMOTE(random_state=0, cluster_balance_threshold=0.001)), ('model', decision_tree_clf)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mean F1-score : 0.901\n",
      "Best parameters :  {'smote__sampling_strategy': 0.6}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline_kmeans_smote,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1_micro\",\n",
    "    n_jobs=-1,\n",
    "    error_score='raise'  # raise an error if any fit fails\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV object on the data\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best mean score and the corresponding parameters\n",
    "print(\"Best mean F1-score : {:.3f}\".format(grid_search.best_score_))\n",
    "print(\"Best parameters : \", grid_search.best_params_)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "pipeline_kmeans_smote_results = cross_validate(pipeline_kmeans_smote, X, y, cv=cv, n_jobs = -1, scoring = \"f1_micro\", return_train_score=True, return_estimator=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score : 0.896\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean F1-score : {:.3f}\".format(np.mean(pipeline_kmeans_smote_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "#save best model\n",
    "best_model = pipeline_kmeans_smote_results['estimator'][np.argmax(pipeline_kmeans_smote_results['test_score'])]\n",
    "filename = './modeles/decision_tree_clf_kmeans_smote_results.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sous-échantillonage"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "pipeline_rus = Pipeline(steps=[('under', RandomUnderSampler(random_state=0)), ('model', decision_tree_clf)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "decision_tree_clf_rus_results = cross_validate(pipeline_rus, X, y, cv=cv, n_jobs = -1, scoring = \"f1_micro\", return_train_score=True, return_estimator=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score : 0.888\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean F1-score : {:.3f}\".format(np.mean(decision_tree_clf_rus_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "#save best model\n",
    "best_model = decision_tree_clf_rus_results['estimator'][np.argmax(decision_tree_clf_rus_results['test_score'])]\n",
    "filename = './modeles/decision_tree_clf_rus_results.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Edited Nearest Neighbour"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "pipeline_enn = Pipeline(steps=[('enn', EditedNearestNeighbours()), ('model', decision_tree_clf)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "decision_tree_clf_enn_results = cross_validate(pipeline_enn, X, y, cv=cv, n_jobs = -1, scoring = \"f1_micro\", return_train_score=True, return_estimator=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score : 0.899\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean F1-score : {:.3f}\".format(np.mean(decision_tree_clf_enn_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#save best model\n",
    "best_model = decision_tree_clf_enn_results['estimator'][np.argmax(decision_tree_clf_enn_results['test_score'])]\n",
    "filename = './modeles/decision_tree_clf_enn_results.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tomek Links"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "pipeline_tomek = Pipeline(steps=[('tomek', TomekLinks()), ('model', decision_tree_clf)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "decision_tree_clf_tomek_results = cross_validate(pipeline_tomek, X, y, cv=cv, n_jobs = -1, scoring = \"f1_micro\", return_train_score=True, return_estimator=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score : 0.901\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean F1-score : {:.3f}\".format(np.mean(decision_tree_clf_tomek_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#save best model\n",
    "best_model = decision_tree_clf_tomek_results['estimator'][np.argmax(decision_tree_clf_tomek_results['test_score'])]\n",
    "filename = './modeles/decision_tree_clf_tomek_results.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Combinaison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RandomOverSampler + RandomUnderSampler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_ros_rus = Pipeline(steps=[\n",
    "    ('over', RandomOverSampler(random_state=0)),\n",
    "    ('under', RandomUnderSampler(random_state=0)),\n",
    "    ('model', DecisionTreeClassifier(random_state=0))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mean F1-score : 0.998\n",
      "Best parameters :  {'over__sampling_strategy': 0.5, 'under__sampling_strategy': 0.6}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the parameter grid for the samplers\n",
    "param_grid = {\n",
    "    'over__sampling_strategy': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'under__sampling_strategy': [0.6, 0.7, 0.8, 0.9, 1]\n",
    "}\n",
    "\n",
    "# Define the GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline_ros_rus,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1_micro\",\n",
    "    n_jobs=-1,\n",
    "    error_score='raise'  # raise an error if any fit fails\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV object on the data\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best mean score and the corresponding parameters\n",
    "print(\"Best mean F1-score : {:.3f}\".format(grid_search.best_score_))\n",
    "print(\"Best parameters : \", grid_search.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "pipeline_ros_rus_results = cross_validate(pipeline_ros_rus, X, y, cv=cv, n_jobs = -1, scoring = \"f1_micro\", return_train_score=True, return_estimator=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score : 0.990\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean F1-score : {:.3f}\".format(np.mean(pipeline_ros_rus_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#save best model\n",
    "best_model = pipeline_ros_rus_results['estimator'][np.argmax(pipeline_ros_rus_results['test_score'])]\n",
    "filename = './modeles/pipeline_ros_rus_results.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Smote + RandomUnderSampler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline_smote_rus = Pipeline(steps=[\n",
    "    ('smote', SMOTE(random_state=0)),\n",
    "    ('under', RandomUnderSampler(random_state=0)),\n",
    "    ('model', DecisionTreeClassifier(random_state=0))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mean F1-score : 0.995\n",
      "Best parameters :  {'smote__sampling_strategy': 0.5, 'under__sampling_strategy': 0.8}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the parameter grid for the samplers\n",
    "param_grid = {\n",
    "    'smote__sampling_strategy': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'under__sampling_strategy': [0.6, 0.7, 0.8, 0.9, 1]\n",
    "}\n",
    "\n",
    "# Define the GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline_smote_rus,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1_micro\",\n",
    "    n_jobs=-1,\n",
    "    error_score='raise'  # raise an error if any fit fails\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV object on the data\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best mean score and the corresponding parameters\n",
    "print(\"Best mean F1-score : {:.3f}\".format(grid_search.best_score_))\n",
    "print(\"Best parameters : \", grid_search.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "pipeline_smote_rus_results = cross_validate(pipeline_smote_rus, X, y, cv=cv, n_jobs = -1, scoring = \"f1_micro\", return_train_score=True, return_estimator=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score : 0.995\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean F1-score : {:.3f}\".format(np.mean(pipeline_smote_rus_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "#save best model\n",
    "best_model = pipeline_smote_rus_results['estimator'][np.argmax(pipeline_smote_rus_results['test_score'])]\n",
    "filename = './modeles/pipeline_smote_rus_results.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SMOTEEEN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score on the test set : 0.994\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "pipeline_smoteenn = Pipeline(steps=[('smoteenn', SMOTEENN(random_state=0)), ('model', decision_tree_clf)])\n",
    "\n",
    "decision_tree_clf_smoteenn_results = cross_validate(pipeline_smoteenn, X, y, cv=cv, scoring='f1_micro', n_jobs=-1, return_train_score=True, return_estimator=True)\n",
    "\n",
    "print(\"Mean F1-score on the test set : {:.3f}\".format(np.mean(decision_tree_clf_smoteenn_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "#save best model\n",
    "best_model = decision_tree_clf_smoteenn_results['estimator'][np.argmax(decision_tree_clf_smoteenn_results['test_score'])]\n",
    "filename = './modeles/decision_tree_clf_smoteenn_results.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SMOTETomek"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score on the test set : 0.995\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "pipeline_smotetomek = Pipeline(steps=[('smotetomek', SMOTETomek(random_state=0)), ('model', decision_tree_clf)])\n",
    "\n",
    "decision_tree_clf_smotetomek_results = cross_validate(pipeline_smotetomek, X, y, cv=cv, scoring='f1_micro', n_jobs=-1, return_train_score=True, return_estimator=True)\n",
    "\n",
    "print(\"Mean F1-score on the test set : {:.3f}\".format(np.mean(decision_tree_clf_smotetomek_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "#save best model\n",
    "best_model = decision_tree_clf_smotetomek_results['estimator'][np.argmax(decision_tree_clf_smotetomek_results['test_score'])]\n",
    "filename = './modeles/decision_tree_clf_smotetomek_results.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Algorithmes sensibles au coût"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Non linéaires"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVC with class_weight = balanced"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#SVC with class_weight = balanced\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_clf_balanced = SVC(class_weight='balanced', random_state=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score on the test set : 0.995\n"
     ]
    }
   ],
   "source": [
    "svc_clf_balanced_results = cross_validate(svc_clf_balanced, X, y, cv=cv, scoring='f1_micro', n_jobs=-1, return_train_score=True, return_estimator=True)\n",
    "\n",
    "print(\"Mean F1-score on the test set : {:.3f}\".format(np.mean(svc_clf_balanced_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#save best model\n",
    "best_model = svc_clf_balanced_results['estimator'][np.argmax(svc_clf_balanced_results['test_score'])]\n",
    "filename = './modeles/svc_clf_balanced_results.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Tree with class_weight = balanced"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree_balanced_clf = DecisionTreeClassifier(class_weight='balanced', random_state=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score on the test set : 0.990\n"
     ]
    }
   ],
   "source": [
    "decision_tree_balanced_clf_results = cross_validate(decision_tree_balanced_clf, X, y, cv=cv, scoring='f1_micro', n_jobs=-1, return_train_score=True, return_estimator=True)\n",
    "\n",
    "print(\"Mean F1-score on the test set : {:.3f}\".format(np.mean(decision_tree_balanced_clf_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#save best model\n",
    "best_model = decision_tree_balanced_clf_results['estimator'][np.argmax(decision_tree_balanced_clf_results['test_score'])]\n",
    "filename = './modeles/decision_tree_balanced_clf_results.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Algorithmes linéaires"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression with class_weight = balanced"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regression_balanced_clf = LogisticRegression(class_weight='balanced', random_state=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score on the test set : 0.973\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_balanced_clf_results = cross_validate(logistic_regression_balanced_clf, X, y, cv=cv, scoring='f1_micro', n_jobs=-1, return_train_score=True, return_estimator=True)\n",
    "\n",
    "print(\"Mean F1-score on the test set : {:.3f}\".format(np.mean(logistic_regression_balanced_clf_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#save best model\n",
    "best_model = logistic_regression_balanced_clf_results['estimator'][np.argmax(logistic_regression_balanced_clf_results['test_score'])]\n",
    "filename = './modeles/logistic_regression_balanced_clf_results.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Algorithmes ensemblistes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bagged Decision Tree with class_weight = balanced"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging_balanced_clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced', random_state=0), random_state=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score on the test set : 0.999\n"
     ]
    }
   ],
   "source": [
    "bagging_balanced_clf_results = cross_validate(bagging_balanced_clf, X, y, cv=cv, scoring='f1_micro', n_jobs=-1, return_train_score=True, return_estimator=True)\n",
    "\n",
    "print(\"Mean F1-score on the test set : {:.3f}\".format(np.mean(bagging_balanced_clf_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#save best model\n",
    "best_model = bagging_balanced_clf_results['estimator'][np.argmax(bagging_balanced_clf_results['test_score'])]\n",
    "filename = './modeles/bagging_balanced_clf_results.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest with class_weight = balanced"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest_baalanced__clf = RandomForestClassifier(class_weight='balanced', random_state=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score on the test set : 0.999\n"
     ]
    }
   ],
   "source": [
    "random_forest_baalanced__clf_results = cross_validate(random_forest_baalanced__clf, X, y, cv=cv, scoring='f1_micro', n_jobs=-1, return_train_score=True, return_estimator=True)\n",
    "\n",
    "print(\"Mean F1-score on the test set : {:.3f}\".format(np.mean(random_forest_baalanced__clf_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "#save best model\n",
    "best_model = random_forest_baalanced__clf_results['estimator'][np.argmax(random_forest_baalanced__clf_results['test_score'])]\n",
    "filename = './modeles/random_forest_baalanced_clf_results.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SGB with class_weight = balanced"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "sgb_balanced_clf = GradientBoostingClassifier(random_state=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score on the test set : 0.901\n"
     ]
    }
   ],
   "source": [
    "sgb_balanced_clf_results = cross_validate(sgb_balanced_clf, X, y, cv=cv, scoring='f1_micro', n_jobs=-1, return_train_score=True, return_estimator=True)\n",
    "\n",
    "print(\"Mean F1-score on the test set : {:.3f}\".format(np.mean(sgb_balanced_clf_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "#save best model\n",
    "best_model = sgb_balanced_clf_results['estimator'][np.argmax(sgb_balanced_clf_results['test_score'])]\n",
    "filename = './modeles/sgb_balanced_clf_results.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Algorithmes à classe unique"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## OneClassSVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "one_class_svm_clf = OneClassSVM()\n",
    "\n",
    "one_class_svm_clf_results = cross_validate(one_class_svm_clf, X, y, cv=cv, scoring='f1_micro', n_jobs=-1, return_train_score=True, return_estimator=True)\n",
    "\n",
    "print(\"Mean F1-score on the test set : {:.3f}\".format(np.mean(one_class_svm_clf_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#save best model\n",
    "best_model = one_class_svm_clf_results['estimator'][np.argmax(one_class_svm_clf_results['test_score'])]\n",
    "filename = './modeles/one_class_svm_clf_results.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Isolation Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score on the test set : 0.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "isolation_forest_clf = IsolationForest(random_state=0)\n",
    "\n",
    "isolation_forest_clf_results = cross_validate(isolation_forest_clf, X, y, cv=cv, scoring='f1_micro', n_jobs=-1, return_train_score=True, return_estimator=True)\n",
    "\n",
    "print(\"Mean F1-score on the test set : {:.3f}\".format(np.mean(isolation_forest_clf_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Minimum Covariance Determinant"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score on the test set : 0.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "minimum_covariance_determinant_clf = EllipticEnvelope(random_state=0)\n",
    "\n",
    "minimum_covariance_determinant_clf_results = cross_validate(minimum_covariance_determinant_clf, X, y, cv=cv, scoring='f1_micro', n_jobs=-1, return_train_score=True, return_estimator=True)\n",
    "\n",
    "print(\"Mean F1-score on the test set : {:.3f}\".format(np.mean(minimum_covariance_determinant_clf_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Local Outlier Factor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score on the test set : nan\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "local_outlier_factor_clf = LocalOutlierFactor()\n",
    "\n",
    "local_outlier_factor_clf_results = cross_validate(local_outlier_factor_clf, X, y, cv=cv, scoring='f1_micro', n_jobs=-1, return_train_score=True, return_estimator=True)\n",
    "\n",
    "print(\"Mean F1-score on the test set : {:.3f}\".format(np.mean(local_outlier_factor_clf_results['test_score'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Threshold tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
